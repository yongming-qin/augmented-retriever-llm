{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6550fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import openai\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "import base_prompt\n",
    "import model as MD\n",
    "import algorithm as AL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "575e094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()    \n",
    "args, unknown = parser.parse_known_args(sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2648365",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93ad7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    # Load data from the specified paths for training and testing\n",
    "\n",
    "    problems_test = json.load(open(args.data_root_test))\n",
    "    problems_train = json.load(open(args.data_root_train))\n",
    "    \n",
    "    if isinstance(problems_test, list):\n",
    "        problems_test = {str(i): item for i, item in enumerate(problems_test)}\n",
    "    if isinstance(problems_train, list):\n",
    "        problems_train = {str(i): item for i, item in enumerate(problems_train)}\n",
    "\n",
    "    problems = {**problems_test, **problems_train}\n",
    "    test_pids = list(problems_test.keys())\n",
    "    train_pids = list(problems_train.keys())\n",
    "\n",
    "    cand_pids = train_pids\n",
    "\n",
    "    # remove the test problems from cand_pids\n",
    "    cand_pids = [pid for pid in cand_pids if pid not in test_pids]\n",
    "\n",
    "    return problems, test_pids, cand_pids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a74e9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "args.data_root_train = \"cluster_results/pubmed/pqaa_train_set.json\"\n",
    "args.data_root_test = \"cluster_results/pubmed/pqaa_dev_set.json\"\n",
    "problems, test_pids, cand_pids = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"QUESTION\": \"Does fGF10 promote regional foetal cardiomyocyte proliferation and adult cardiomyocyte cell-cycle re-entry?\",\n",
      "  \"CONTEXTS\": [\n",
      "    \"Cardiomyocyte proliferation gradually declines during embryogenesis resulting in severely limited regenerative capacities in the adult heart. Understanding the developmental processes controlling cardiomyocyte proliferation may thus identify new therapeutic targets to modulate the cell-cycle activity of cardiomyocytes in the adult heart. This study aims to determine the mechanism by which fibroblast growth factor 10 (FGF10) controls foetal cardiomyocyte proliferation and to test the hypothesis that FGF10 promotes the proliferative capacity of adult cardiomyocytes.\",\n",
      "    \"Analysis of Fgf10(-/-) hearts and primary cardiomyocyte cultures reveals that altered ventricular morphology is associated with impaired proliferation of right but not left-ventricular myocytes. Decreased FOXO3 phosphorylation associated with up-regulated p27(kip) (1) levels was observed specifically in the right ventricle of Fgf10(-/-) hearts. In addition, cell-type-specific expression analysis revealed that Fgf10 and its receptor, Fgfr2b, are expressed in cardiomyocytes and not cardiac fibroblasts, consistent with a cell-type autonomous role of FGF10 in regulating regional specific myocyte proliferation in the foetal heart. Furthermore, we demonstrate that in vivo overexpression of Fgf10 in adult mice promotes cardiomyocyte but not cardiac fibroblast cell-cycle re-entry.\"\n",
      "  ],\n",
      "  \"LABELS\": [\n",
      "    \"OBJECTIVE\",\n",
      "    \"RESULTS\"\n",
      "  ],\n",
      "  \"LONG_ANSWER\": \"FGF10 regulates regional cardiomyocyte proliferation in the foetal heart through a FOXO3/p27(kip1) pathway. In addition, FGF10 triggers cell-cycle re-entry of adult cardiomyocytes and is thus a potential target for cardiac repair.\",\n",
      "  \"MESHES\": [\n",
      "    \"Animals\",\n",
      "    \"Cell Cycle\",\n",
      "    \"Cell Proliferation\",\n",
      "    \"Cells, Cultured\",\n",
      "    \"Cyclin-Dependent Kinase Inhibitor p27\",\n",
      "    \"Fibroblast Growth Factor 10\",\n",
      "    \"Forkhead Box Protein O3\",\n",
      "    \"Forkhead Transcription Factors\",\n",
      "    \"Heart\",\n",
      "    \"Mice\",\n",
      "    \"Myocytes, Cardiac\"\n",
      "  ],\n",
      "  \"final_decision\": \"yes\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(problems[test_pids[0]], indent=2))\n",
    "# the problem contains solution (CONTESTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81e47e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate prompts: \n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# Create examples\n",
    "## choices=['T-A', 'Q-A', 'Q-AS', 'Q-SA', 'TQ-A', 'TQ-AS', 'TQ-SA', 'QT-A', 'QT-AS', 'QT-SA', 'QTS-A', 'TQS-A']\n",
    "from base_prompt import create_example_from_pid \n",
    "args.prompt_format = 'Q-A'\n",
    "\n",
    "print(\"candidate prompts: \")\n",
    "print(\"===========\")\n",
    "cand_examples = []\n",
    "\n",
    "args.option_inds = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\",\n",
    "                                \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "for pid in cand_pids:\n",
    "    example = create_example_from_pid(pid, problems, args, test=False)  # CHECK !!!\n",
    "    #print(example)\n",
    "    #print(\"===========\")\n",
    "    cand_examples.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18a93fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_examples_test = cand_examples[:10]  # use only 10 examples for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e8ce8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: Does intraperitoneal kisspeptin-10 administration induce dose-dependent degenerative changes in maturing rat testes?\\nAnswer: The answer is yes.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e846d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Question: Does intraperitoneal kisspeptin-10 administration induce dose-dependent degenerative changes in maturing rat testes?\\nAnswer: The answer is yes. BECAUSE: Kisspeptin, a peptide secreted by hypothalamic neurons, is a critical regulator of reproduction and puberty but its role in the regulation of gonadal maturation in sexually immature males is elusive. The present study investigated the effects of 12 days of pulsatile kisspeptin administration on gonadotropins and testosterone release and maturation of immature male gonads.Kisspeptin-10 was administered intraperitoneally at different dosage concentrations (1 μg, 1 ng, and 10 pg) to 5 weeks old prepubertal male rats, twice daily for 12 days. Plasma LH, FSH and testosterone concentrations were measured through competitive-binding radioimmunoassay. Spermatogenesis was studied mainly at stage VII of the spermatogenic cycle through light and electron microscopy.At the end of the treatments plasma LH and testosterone concentrations were reduced significantly at 1ng and 1μg kisspeptin doses (P<0.05; P<0.01). Type A spermatogonia, preleptotene spermatocytes, pachytene spermatocytes, step 7 spermatids, elongated spermatids and daily sperm production decreased significantly (P<0.05). Sertoli cell efficiency and total support capacity of Sertoli cells were reduced at all doses (P<0.05). Meiotic index decreased (P<0.05) at 1 μg dose only, whereas coefficient of mitosis increased at 1 ng and 1 μg (P<0.01) kisspeptin doses. Histologically, degeneration of seminiferous tubules was evident showing tubular necrosis, multinucleated giant cell formation, intratubular vacuolization, widened lumen and deshaped germ cells. Marked ultrastructural changes characterized by thin basal laminae, enlarged intratubular spaces, abnormal acrosome and disrupted germ cells were noticeable.'\n",
    "\n",
    "\n",
    "'Question: Does intraperitoneal kisspeptin-10 administration induce dose-dependent degenerative changes in maturing rat testes?\\nAnswer: The answer is yes.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dcf4ad",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee18d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_config: bert-base-uncased\n",
      "Scores for the first 10 candidate examples:\n",
      "tensor([[ 1.5951e-01, -2.6128e-01,  3.4357e-01,  ..., -6.5362e-02,\n",
      "          1.2093e-01, -1.8131e-01],\n",
      "        [ 2.4021e-03, -2.5278e-01,  3.1830e-01,  ..., -1.8675e-01,\n",
      "         -4.3930e-02, -2.2702e-01],\n",
      "        [-8.8072e-03, -1.3110e-01,  2.9783e-01,  ..., -1.1066e-01,\n",
      "         -5.4490e-02,  4.1309e-04],\n",
      "        ...,\n",
      "        [ 1.1394e-01, -3.0882e-01,  4.1161e-01,  ...,  4.6223e-02,\n",
      "         -7.9045e-03, -7.7852e-02],\n",
      "        [ 1.1195e-01, -2.2459e-01,  4.4036e-01,  ..., -5.4452e-02,\n",
      "          1.1512e-01, -1.3236e-01],\n",
      "        [ 3.2664e-02, -1.1969e-01,  4.3586e-01,  ..., -1.6499e-01,\n",
      "          8.8950e-03, -1.6951e-01]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from model import policy_network\n",
    "ctxt_list = [problems[pid] for pid in test_pids]\n",
    "cands_list = [problems[pid] for pid in cand_pids]\n",
    "\n",
    "model = policy_network(model_config=\"bert-base-uncased\", add_linear=True, embedding_size=256)\n",
    "\n",
    "\n",
    "scores = model(cand_examples_test)\n",
    "print(\"Scores for the first 10 candidate examples:\")\n",
    "print(type(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48a4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59734f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QUESTION': 'Does fGF10 promote regional foetal cardiomyocyte proliferation and adult cardiomyocyte cell-cycle re-entry?',\n",
       " 'CONTEXTS': ['Cardiomyocyte proliferation gradually declines during embryogenesis resulting in severely limited regenerative capacities in the adult heart. Understanding the developmental processes controlling cardiomyocyte proliferation may thus identify new therapeutic targets to modulate the cell-cycle activity of cardiomyocytes in the adult heart. This study aims to determine the mechanism by which fibroblast growth factor 10 (FGF10) controls foetal cardiomyocyte proliferation and to test the hypothesis that FGF10 promotes the proliferative capacity of adult cardiomyocytes.',\n",
       "  'Analysis of Fgf10(-/-) hearts and primary cardiomyocyte cultures reveals that altered ventricular morphology is associated with impaired proliferation of right but not left-ventricular myocytes. Decreased FOXO3 phosphorylation associated with up-regulated p27(kip) (1) levels was observed specifically in the right ventricle of Fgf10(-/-) hearts. In addition, cell-type-specific expression analysis revealed that Fgf10 and its receptor, Fgfr2b, are expressed in cardiomyocytes and not cardiac fibroblasts, consistent with a cell-type autonomous role of FGF10 in regulating regional specific myocyte proliferation in the foetal heart. Furthermore, we demonstrate that in vivo overexpression of Fgf10 in adult mice promotes cardiomyocyte but not cardiac fibroblast cell-cycle re-entry.'],\n",
       " 'LABELS': ['OBJECTIVE', 'RESULTS'],\n",
       " 'LONG_ANSWER': 'FGF10 regulates regional cardiomyocyte proliferation in the foetal heart through a FOXO3/p27(kip1) pathway. In addition, FGF10 triggers cell-cycle re-entry of adult cardiomyocytes and is thus a potential target for cardiac repair.',\n",
       " 'MESHES': ['Animals',\n",
       "  'Cell Cycle',\n",
       "  'Cell Proliferation',\n",
       "  'Cells, Cultured',\n",
       "  'Cyclin-Dependent Kinase Inhibitor p27',\n",
       "  'Fibroblast Growth Factor 10',\n",
       "  'Forkhead Box Protein O3',\n",
       "  'Forkhead Transcription Factors',\n",
       "  'Heart',\n",
       "  'Mice',\n",
       "  'Myocytes, Cardiac'],\n",
       " 'final_decision': 'yes'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctxt_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27748e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_config: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from model import policy_network\n",
    "\n",
    "args.model_config = 'bert-base-uncased'\n",
    "args.embedding_size = 128\n",
    "\n",
    "policy_model = policy_network(model_config=args.model_config,\n",
    "                                add_linear=True,\n",
    "                                embedding_size=args.embedding_size,\n",
    "                                freeze_encoder=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy_model = policy_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_cands = policy_model(cand_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547213d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_config: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "## configure the model. --algorithm', default='ERM',\n",
    "args.algorithm = 'ERM'\n",
    "\n",
    "num_train_domains = 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Main model\n",
    "## policy network, get the tokenizer and the encoder from the pretrained model\n",
    "model = MD.policy_network(model_config= args.model_config,\n",
    "                          add_linear=True,\n",
    "                          embedding_size=args.embedding_size,\n",
    "                          freeze_encoder=True)\n",
    "\n",
    "model = model.to(device) \n",
    "\n",
    "# Loss fn\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Algorithm\n",
    "hparams = {}\n",
    "hparams['support_size'] = args.batch_size // args.meta_batch_size\n",
    "hparams['batch_size'] = args.batch_size\n",
    "\n",
    "args.lr = 1e-4\n",
    "algorithm = AL.ERM(model, loss_fn, device, 'adam', args.lr, hparams=hparams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3fc7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_config',\n",
    "                    type=str,\n",
    "                    default='bert-base-uncased',\n",
    "                    choices=['distilbert-base-uncased', 'bert-base-uncased'])\n",
    "parser.add_argument('--embedding_size', type=int, default=128, help='Policy network final layer hidden state size.')\n",
    "parser.add_argument('--algorithm', type=str, default='ERM',\n",
    "                    choices=['ERM', 'DRNN', 'ARM-CML', 'ARM-BN', 'ARM-LL', 'DANN', 'MMD'])\n",
    "parser.add_argument('--batch_size', type=int, default=50)\n",
    "    \n",
    "args, unknown = parser.parse_known_args(sys.argv)\n",
    "args.meta_batch_size = args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1e6513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here’s a classic for you: \n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai.api_key = \"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\"  # Replace with your OpenAI API key\n",
    "\n",
    "client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a joke.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "152bc229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211269\n"
     ]
    }
   ],
   "source": [
    "print(len(problems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4098a9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mproblems\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: '0'"
     ]
    }
   ],
   "source": [
    "problems['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db0b7438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate prompts: \n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get result file path\n",
    "result_file = \"results/results.json\"\n",
    "results = {}\n",
    "\n",
    "total = len(pids)\n",
    "check_count = len(results)\n",
    "correct = 0\n",
    "\n",
    "# Prepare candidate examples\n",
    "print(\"candidate prompts: \")\n",
    "print(\"===========\")\n",
    "cand_examples = []\n",
    "for pid in cand_pids:\n",
    "    example =  create_example_from_pid(pid, problems, args,  test=True)\n",
    "    cand_examples.append(example)\n",
    "\n",
    "new_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_output(prompt, args):\n",
    "    if \"gpt4\" in args.engine:\n",
    "        user_prompt = \"Please answer yes or no or maybe for the question.\"\n",
    "\n",
    "        user_prompt = \"Please choose from all the options follow the given example.\"\n",
    "\n",
    "        user_prompt = \"Follow the given examples and answer the question following the same format.\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=OPENAI_DEPLOYMENT_MODEL,\n",
    "            # The deployment name you chose when you deployed the GPT-35-Turbo or GPT-4 model.\n",
    "            messages=[{\n",
    "                \"role\": \"system\", \"content\": prompt\n",
    "            },\n",
    "                {\n",
    "        \"role\": \"user\", \"content\": user_prompt\n",
    "    }],\n",
    "            temperature=0.0, max_tokens=args.max_tokens, top_p=1, frequency_penalty=args.frequency_penalty, presence_penalty=args.presence_penalty)\n",
    "        output = response.choices[0].message.content\n",
    "        if output is not None:\n",
    "            if output.startswith(\"\\n\\n\"):\n",
    "                output = output[2:]\n",
    "            output = output.split(\"\\n\")[0]\n",
    "    else:\n",
    "        response = openai.Completion.create(engine=args.engine,\n",
    "                                            prompt=prompt,\n",
    "                                            temperature=args.temperature,\n",
    "                                            max_tokens=args.max_tokens,\n",
    "                                            top_p=args.top_p,\n",
    "                                            frequency_penalty=args.frequency_penalty,\n",
    "                                            presence_penalty=args.presence_penalty,\n",
    "                                            stop=[\"\\n\"])\n",
    "        output = response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f371e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    args = parse_args()\n",
    "    print('====Input Arguments====')\n",
    "    print(json.dumps(vars(args), indent=2, sort_keys=False))\n",
    "\n",
    "    # https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)  # CPU random seed\n",
    "    torch.cuda.manual_seed(args.seed)  # GPU random seed\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    algorithm = init_algorithm(args)\n",
    "    # problems, test question ids, candidate prompt pids, RL training pids\n",
    "    problems, pids, cand_pids = load_data(args)\n",
    "\n",
    "    result_file = get_result_file(args)\n",
    "\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    total = len(pids)\n",
    "    check_count = len(results)  # number of existing results\n",
    "    correct = 0  # number of correct results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"candidate prompts: \")\n",
    "    print(\"===========\")\n",
    "    cand_examples = []\n",
    "    for pid in cand_pids:\n",
    "        example = create_example_from_pid(pid, problems, args, test=True)  # CHECK !!!\n",
    "        #print(example)\n",
    "        #print(\"===========\")\n",
    "        cand_examples.append(example)\n",
    "    if args.train_ckpt:\n",
    "        train_pids = torch.load(args.train_ckpt)\n",
    "        train_pids = [i for i in train_pids if i not in pids]\n",
    "        val_examples = []\n",
    "        for pid in train_pids:\n",
    "            val_example = create_example_from_pid(pid, problems, args, test=True)  # CHECK !!!\n",
    "            # print(example)\n",
    "            # print(\"===========\")\n",
    "            val_examples.append(val_example)\n",
    "        if args.val_ckpt:\n",
    "            val_pids = torch.load(args.val_ckpt)\n",
    "            correct_val_pids = [i for i in val_pids if i not in train_pids]\n",
    "            correct_val_examples = []\n",
    "            for pid in correct_val_pids:\n",
    "                correct_val_example = create_example_from_pid(pid, problems, args, test=True)  # CHECK !!!\n",
    "                # print(example)\n",
    "                # print(\"===========\")\n",
    "                correct_val_examples.append(correct_val_example)\n",
    "\n",
    "    if args.aug_method == 'hints':\n",
    "        aug_label = []\n",
    "        for i in cluster_num.keys():\n",
    "            if cluster_num[i] <= args.aug_th:\n",
    "                aug_label.append(i)\n",
    "        print(\"aug label\", aug_label)\n",
    "        cluster_train_id = [i for i in range(len(cluster_id)) if cluster_id[i] in aug_label]\n",
    "\n",
    "        # #subsample cluster_train_id\n",
    "        # cluster_train_id = random.sample(cluster_train_id, 60)\n",
    "\n",
    "\n",
    "        examples_train_aug = [cand_examples[i] for i in cluster_train_id]\n",
    "        embeddings = [embeddings[i] for i in cluster_train_id]\n",
    "        cluster_id_aug = [cluster_id[i] for i in cluster_train_id]\n",
    "\n",
    "        # cluster_num = {}\n",
    "        # for i in cluster_id_aug:\n",
    "        #     if i not in cluster_num.keys():\n",
    "        #         cluster_num[i] = 1\n",
    "        #     else:\n",
    "        #         cluster_num[i] = cluster_num[i] + 1\n",
    "        # print(\"after reducing samples:\", cluster_num)\n",
    "\n",
    "        print(\"len train\", len(examples_train_aug))\n",
    "        print(\"len embeddings\", len(embeddings))\n",
    "        print(\"len cluster id\", len(cluster_id_aug))\n",
    "        new_samples = hint_aug(args, examples_train_aug, embeddings, cluster_id_aug)\n",
    "    elif args.aug_method == 'seed':\n",
    "        seed_sentence = torch.load(\n",
    "            f\"cluster_results/seed_sentence_{args.cluster_type}_{args.n_clusters}_1000.pt\")\n",
    "        print(\n",
    "            f\"Load seed sentence from cluster_results/seed_sentence_{args.cluster_type}_{args.n_clusters}_1000.pt\")\n",
    "        print(\"generate augmented samples using seed sentences.\")\n",
    "        new_samples = seed_aug(args, seed_sentence)\n",
    "    else:\n",
    "        new_samples = []\n",
    "    #print(\"len(examples_train)\", len(examples_train)\n",
    "\n",
    "    #generate new pids\n",
    "    new_pids = []\n",
    "    for i in range(len(new_samples)):\n",
    "        if i not in cand_pids:\n",
    "            new_pids.append(i)\n",
    "        else:\n",
    "            print(\"id already exists!\")\n",
    "            exit(0)\n",
    "\n",
    "    #combine cand samples and augmented samples\n",
    "    cand_examples.extend(new_samples)\n",
    "    cand_pids.extend(new_pids)\n",
    "    for i in range(len(new_samples)):\n",
    "        problems.update({new_pids[i]: {'new_samples': new_samples[i]}})\n",
    "    print(\"Extended cand size\", len(cand_pids))\n",
    "    test_examples = []\n",
    "    for pid in pids:\n",
    "        if 'medqa' in args.data_root_test or args.data_root_test in ['ethos-national_origin'\n",
    "                                                                           'tweet_eval-emoji']:\n",
    "            pid = int(pid)\n",
    "        example = create_example_from_pid(pid, problems, args, test=True)  # CHECK !!!\n",
    "        test_examples.append(example)\n",
    "\n",
    "    # ======================================================= INFERENCE ===============================================\n",
    "    if args.ckpt:\n",
    "        ckpt_path = os.path.join(args.ckpt_root, args.ckpt)\n",
    "        if args.ckpt_context:\n",
    "            ckpt_context_path = os.path.join(args.ckpt_root, args.ckpt_context)\n",
    "            if os.path.exists(ckpt_context_path):\n",
    "                algorithm.context_net.linear.load_state_dict(torch.load(ckpt_context_path))\n",
    "                print(\"context model loaded\")\n",
    "            else:\n",
    "                print(f\"The ckpt path for [{ckpt_context_path}] does not exist!\")\n",
    "        if args.ckpt_lossnet:\n",
    "            ckpt_lossnet_path = os.path.join(args.ckpt_root, args.ckpt_lossnet)\n",
    "            if os.path.exists(ckpt_lossnet_path):\n",
    "                algorithm.learned_loss_net.load_state_dict(torch.load(ckpt_lossnet_path))\n",
    "                print(\"Loss net loaded\")\n",
    "            else:\n",
    "                print(f\"The ckpt path for [{ckpt_lossnet_path}] does not exist!\")\n",
    "\n",
    "        if os.path.exists(ckpt_path):\n",
    "            algorithm.model.linear.load_state_dict(torch.load(ckpt_path))\n",
    "            print(\"Policy model loaded\")\n",
    "        else:\n",
    "            print(f\"The ckpt path for [{ckpt_path}] does not exist!\")  # CHECK\n",
    "            #exit()\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(f\"!!! Load the pre-traind model instead!\")  # CHECK\n",
    "        #exit()\n",
    "\n",
    "    algorithm.model.eval()\n",
    "        # Calculate the embeddings for candidate examples only one time!\n",
    "    #with torch.no_grad():\n",
    "    cand_embedding = algorithm.predict(cand_examples)\n",
    "    if args.train_ckpt:\n",
    "        val_embedding = algorithm.predict(val_examples)\n",
    "        if args.val_ckpt:\n",
    "            correct_val_embedding = algorithm.predict(correct_val_examples)\n",
    "    wrong_max_scores = []\n",
    "    correct_max_scores = []\n",
    "    wrong_max_scores_true = []\n",
    "    correct_max_scores_true = []\n",
    "    shot_len_avg = []\n",
    "    if args.preselection:\n",
    "        original_cand_pids = copy.deepcopy(cand_pids)\n",
    "    with torch.no_grad():\n",
    "        for i, pid in enumerate(pids):\n",
    "            if 'medqa' in args.data_root_test or args.data_root_test in ['ethos-national_origin',\n",
    "                                                                           'tweet_eval-emoji']:\n",
    "                pid = int(pid)\n",
    "            count = i + 1  # number of current results\n",
    "            problem = problems[pid]\n",
    "            # if 'solution' not in problems[pid].keys():\n",
    "            #     _, _, answer = problems[pid]['answer'].partition(\"\\n#### \")\n",
    "            # else:\n",
    "            #     answer = problems[pid]['answer']\n",
    "            if 'tabmwp' in args.data_root_test or 'medqa' in args.data_root_test:\n",
    "                answer = problem['answer']\n",
    "            elif 'gsm8k' in args.data_root_test:\n",
    "                _, _, answer = problem['answer'].partition(\"\\n#### \")\n",
    "            elif 'MATH' in args.data_root_test:\n",
    "                answer = remove_boxed(last_boxed_only_string(problem[\"solution\"]))\n",
    "            elif 'pubmed' in args.data_root_test:\n",
    "                answer = problem['final_decision']\n",
    "            elif \"output\" in problem.keys():\n",
    "                answer = problem['output']\n",
    "            else:\n",
    "                raise Exception(\"The dataset does not exist!\")\n",
    "            if \"options\" in problem.keys():\n",
    "                if 'medqa' in args.data_root_test:\n",
    "                    options = []\n",
    "                    for o in problems[pid]['options'].keys():\n",
    "                        options.append(problems[pid]['options'][o])\n",
    "                else:\n",
    "                    options = problems[pid]['options']\n",
    "            elif \"choices\" in problem.keys():\n",
    "                options = problems[pid]['choices']\n",
    "            else:\n",
    "                options = None\n",
    "            if 'unit' in problems[pid].keys():\n",
    "                unit = problems[pid]['unit']\n",
    "            else:\n",
    "                unit = None\n",
    "            if str(pid) in results:\n",
    "                pid = str(pid)\n",
    "                output = results[pid][\"output\"]\n",
    "                shot_len_avg.append(len(results[pid][\"shot_pids\"]))\n",
    "            else:\n",
    "\n",
    "                example = create_example_from_pid(pid, problems, args, test=True)\n",
    "                if args.preselection:\n",
    "                    Cand_example = bm25_retrieve(example, cand_examples, n=args.select_number)\n",
    "                    cand_idx = bm25_retrieve(example, cand_examples, n=args.select_number, return_index=True).tolist()\n",
    "                    cand_pids = [original_cand_pids[c] for c in cand_idx]\n",
    "                    cand_embedding = algorithm.predict(Cand_example)\n",
    "                # if i < 10:\n",
    "                if args.gamma != 0:\n",
    "                    ctxt_embedding, _ = algorithm.predict([example], test=True)\n",
    "                else:\n",
    "                    ctxt_embedding = algorithm.predict([example], test=True)\n",
    "\n",
    "                scores = F.softmax(torch.mm(ctxt_embedding, cand_embedding.t()), dim=1)[0]  # [cand_num]\n",
    "                # print(scores.shape)\n",
    "                scores = scores.cpu().detach().numpy().tolist()\n",
    "                score_th = args.score_th\n",
    "                if args.train_ckpt:\n",
    "                    val_scores = F.softmax(torch.mm(val_embedding, cand_embedding.t()), dim=1)  # [cand_num]\n",
    "                    val_scores = val_scores.cpu().detach().numpy()\n",
    "                    # print(len(scores), val_scores.shape)\n",
    "                    val_mean, val_std = np.mean(val_scores, axis=0), np.std(val_scores, axis=0)\n",
    "                    # print(f\"get mean {val_mean} and std {val_std} for validation data!\")\n",
    "                    score_th = (args.score_th - val_mean) + scores\n",
    "                    # print(f\"The adjust score_th is {score_th}\")\n",
    "                if args.val_ckpt:\n",
    "                    correct_val_scores = F.softmax(torch.mm(ctxt_embedding, correct_val_embedding.t()), dim=1)[\n",
    "                        0]  # [cand_num]\n",
    "                    # print(scores.shape)\n",
    "                    correct_val_scores = correct_val_scores.cpu().detach().numpy().tolist()\n",
    "\n",
    "                shot_pids = []\n",
    "                # if max(scores) > score_th:\n",
    "                cand_ids = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:args.shot_number]\n",
    "                for cid in cand_ids[::-1]:\n",
    "                    if args.train_ckpt is None:\n",
    "                        if scores[cid] > score_th:\n",
    "                            shot_pids.append(cand_pids[cid])\n",
    "                    else:\n",
    "                        if scores[cid] > score_th[cid]:\n",
    "                            shot_pids.append(cand_pids[cid])\n",
    "\n",
    "                shot_len_avg.append(len(shot_pids))\n",
    "\n",
    "                prompt_no_test = build_prompt(problems, shot_pids, pid, args, include_test=False)\n",
    "\n",
    "                prompt = build_prompt(problems, shot_pids, pid, args)  # generate the prompt input\n",
    "\n",
    "                # if str(pid) in results:\n",
    "                #     output = results[str(pid)][\"output\"]\n",
    "                # else:\n",
    "                output = get_gpt_output(prompt, args)  # generate the output by GPT-3\n",
    "\n",
    "            if 'tabmwp' in args.data_root_test or 'medqa' in args.data_root_test:\n",
    "                # the core prediction in the output\n",
    "                if output:\n",
    "                    prediction = extract_prediction(output, options, args.option_inds)\n",
    "                    prediction_norm = normalize_answer(prediction, unit)\n",
    "                else:\n",
    "                    prediction = output\n",
    "                    prediction_norm = output\n",
    "\n",
    "                # normalize the number in the text\n",
    "                answer_norm = normalize_answer(answer, unit)\n",
    "\n",
    "            elif 'pubmed' in args.data_root_test:\n",
    "                answer_norm = answer\n",
    "                prediction = extract_prediction(output, options, args.option_inds)\n",
    "                prediction_norm = prediction\n",
    "            else:\n",
    "                # the core prediction in the output\n",
    "                if output:\n",
    "\n",
    "                    prediction = remove_boxed(last_boxed_only_string(output))\n",
    "\n",
    "                    if not prediction:\n",
    "                        prediction = extract_prediction(output, options, args.option_inds)\n",
    "                else:\n",
    "                    prediction = output\n",
    "\n",
    "                # normalize the number in the text\n",
    "                if answer:\n",
    "                    # answer = normalize_answer(answer, unit)\n",
    "                    # prediction = normalize_answer(prediction, unit)\n",
    "                    answer_norm = _strip_string(answer)\n",
    "                    # answer_norm = answer\n",
    "                    if prediction:\n",
    "                        prediction_norm = _strip_string(prediction)\n",
    "                    else:\n",
    "                        prediction_norm = prediction\n",
    "\n",
    "            if answer:\n",
    "                if str(pid) not in results:\n",
    "                    # save the results\n",
    "                    results[pid] = {}\n",
    "\n",
    "                    results[pid][\"shot_pids\"] = shot_pids\n",
    "                    results[pid][\"prompt\"] = prompt\n",
    "                    results[pid][\"answer\"] = answer\n",
    "                    results[pid][\"answer_norm\"] = answer_norm\n",
    "                    results[pid][\"output\"] = output\n",
    "                    results[pid][\"prediction\"] = prediction\n",
    "                    results[pid][\"prediction_norm\"] = prediction_norm\n",
    "                    # if args.duplicate_sample > 0:\n",
    "                    #     results[pid][\"duplicate_sample\"] = new_sample\n",
    "                else:\n",
    "                    shot_pids = results[pid][\"shot_pids\"]\n",
    "                    prompt = results[pid][\"prompt\"]\n",
    "                    answer = results[pid][\"answer\"]\n",
    "                    answer_norm = results[pid][\"answer_norm\"]\n",
    "                    output = results[pid][\"output\"]\n",
    "                    prediction = results[pid][\"prediction\"]\n",
    "                    prediction_norm = results[pid][\"prediction_norm\"]\n",
    "\n",
    "\n",
    "\n",
    "                # correct or not\n",
    "                if prediction_norm:\n",
    "                    if answer_norm.lower() in prediction_norm.lower():\n",
    "                        correct += 1\n",
    "                        results[pid][\"true_false\"] = True\n",
    "                        # if args.train_ckpt:\n",
    "                        #     correct_max_scores.append(max(val_scores))\n",
    "                        #     if args.val_ckpt:\n",
    "                        #         correct_max_scores_true.append(max(correct_val_scores))\n",
    "                    else:\n",
    "                        results[pid][\"true_false\"] = False\n",
    "                        # if args.train_ckpt:\n",
    "                        #     wrong_max_scores.append(max(val_scores))\n",
    "                        #     if args.val_ckpt:\n",
    "                        #         wrong_max_scores_true.append(max(correct_val_scores))\n",
    "                else:\n",
    "                    results[pid][\"true_false\"] = False\n",
    "\n",
    "                acc = correct / (i + 1) * 100\n",
    "\n",
    "                if args.debug or i < 10:\n",
    "                    print(\"\\n##################################\")\n",
    "                    print(prompt, \"\\n\")\n",
    "                    print(\"[A] labeled answer (normalized):\\t\", answer_norm)\n",
    "                    print(\"[P] predicted answer (normalized):\\t\", prediction_norm)\n",
    "                    print(\"[Acc]:\\t\", results[pid][\"true_false\"])\n",
    "                    print(\"\")\n",
    "                    print(\"[A] labeled answer:\\t\", answer)\n",
    "                    print(\"[P] predicted answer:\\t\", prediction)\n",
    "                    print(\"[P] generated output:\\t\", output)\n",
    "\n",
    "                if count % args.save_every == 0 or count == total:\n",
    "                    avg_len = sum(shot_len_avg)/len(shot_len_avg)\n",
    "                    if count >= check_count:\n",
    "                        # have new outputs\n",
    "                        print(f\"{count}/{total}, correct: {correct}, acc: {round(acc, 2)}%, avg shot number {avg_len}, saved to {result_file}\")\n",
    "                        save_results(result_file, acc, correct, count, cand_pids, args, results)\n",
    "                    else:\n",
    "                        # no new outputs, just print the accuracy\n",
    "                        print(f\"{count}/{total}, correct: {correct}, acc: {round(acc, 2)}%, avg shot number {avg_len}\")\n",
    "                    # if args.train_ckpt:\n",
    "                    #     if len(wrong_max_scores) > 0:\n",
    "                    #         print(f\"wrong max score for false val: {sum(wrong_max_scores)/len(wrong_max_scores)}, wrong max score for correct val: {sum(wrong_max_scores_true)/len(wrong_max_scores_true)}\")\n",
    "                    #     if len(correct_max_scores) > 0:\n",
    "                    #         print(f\"correct max score for false val: {sum(correct_max_scores) / len(correct_max_scores)}, correct max score for correct val: {sum(correct_max_scores_true) / len(correct_max_scores_true)}\")\n",
    "                    #\n",
    "                    #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b2ce4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=111\n"
     ]
    }
   ],
   "source": [
    "a = 111\n",
    "\n",
    "print(f\"{a=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7390c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxi/Foxx/ai-agent/rag/augmented-retriever-llm/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfa5878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f\"Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "313cb7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Token  Token ID  Attention Mask\n",
      "0   [CLS]       101               1\n",
      "1     the      1996               1\n",
      "2   quick      4248               1\n",
      "3   brown      2829               1\n",
      "4     fox      4419               1\n",
      "5   jumps     14523               1\n",
      "6    over      2058               1\n",
      "7     the      1996               1\n",
      "8    lazy     13971               1\n",
      "9     dog      3899               1\n",
      "10      .      1012               1\n",
      "11  [SEP]       102               1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "encoded = tokenizer(sentence, return_tensors='pt', return_attention_mask=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded['input_ids'][0])\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "attention_mask = encoded.attention_mask[0]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Token': tokens,\n",
    "    'Token ID': token_ids,\n",
    "    'Attention Mask': attention_mask\n",
    "})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d03ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5788, 7522, 4411, 8978, 9976, 93, 6286, 8396, 2117, 8498, 9197, 3366, 6981, 919, 7882, 5975, 9338, 9083, 3274, 8269, 6773, 7945, 5845, 6789, 5670, 25, 8822, 8849, 10034, 5425, 7506, 9828, 458, 3761, 2903, 9023, 9575, 2961, 1500, 9028, 4182, 531, 1154, 1363, 273, 7421, 238, 4607, 4088, 4401]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example: load a file\n",
    "file_path = 'cluster_results/cand_medqa_erm_100.pt'\n",
    "data = torch.load(file_path, map_location='cpu')  \n",
    "\n",
    "# Inspect the contents\n",
    "print(data)  # Number of items in the file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a345802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_data)=200000\n",
      "len(dev_data)=11269\n",
      "len(ori_data)=211269\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('cluster_results/pubmed/pqaa_train_set.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(f'{len(train_data)=}')  # Print test data length\n",
    "\n",
    "with open('cluster_results/pubmed/pqaa_dev_set.json', 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "print(f'{len(dev_data)=}')  # Print dev data length\n",
    "\n",
    "with open('cluster_results/pubmed/ori_pqaa.json', 'r') as f:\n",
    "    ori_data = json.load(f)\n",
    "print(f'{len(ori_data)=}')  # Print original data length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f024a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First train example: {\n",
      "  \"QUESTION\": \"Does intraperitoneal kisspeptin-10 administration induce dose-dependent degenerative changes in maturing rat testes?\",\n",
      "  \"CONTEXTS\": [\n",
      "    \"Kisspeptin, a peptide secreted by hypothalamic neurons, is a critical regulator of reproduction and puberty but its role in the regulation of gonadal maturation in sexually immature males is elusive. The present study investigated the effects of 12 days of pulsatile kisspeptin administration on gonadotropins and testosterone release and maturation of immature male gonads.\",\n",
      "    \"Kisspeptin-10 was administered intraperitoneally at different dosage concentrations (1 \\u03bcg, 1 ng, and 10 pg) to 5 weeks old prepubertal male rats, twice daily for 12 days. Plasma LH, FSH and testosterone concentrations were measured through competitive-binding radioimmunoassay. Spermatogenesis was studied mainly at stage VII of the spermatogenic cycle through light and electron microscopy.\",\n",
      "    \"At the end of the treatments plasma LH and testosterone concentrations were reduced significantly at 1ng and 1\\u03bcg kisspeptin doses (P<0.05; P<0.01). Type A spermatogonia, preleptotene spermatocytes, pachytene spermatocytes, step 7 spermatids, elongated spermatids and daily sperm production decreased significantly (P<0.05). Sertoli cell efficiency and total support capacity of Sertoli cells were reduced at all doses (P<0.05). Meiotic index decreased (P<0.05) at 1 \\u03bcg dose only, whereas coefficient of mitosis increased at 1 ng and 1 \\u03bcg (P<0.01) kisspeptin doses. Histologically, degeneration of seminiferous tubules was evident showing tubular necrosis, multinucleated giant cell formation, intratubular vacuolization, widened lumen and deshaped germ cells. Marked ultrastructural changes characterized by thin basal laminae, enlarged intratubular spaces, abnormal acrosome and disrupted germ cells were noticeable.\"\n",
      "  ],\n",
      "  \"LABELS\": [\n",
      "    \"OBJECTIVE\",\n",
      "    \"METHODS\",\n",
      "    \"RESULTS\"\n",
      "  ],\n",
      "  \"LONG_ANSWER\": \"In conclusion long-term kisspeptin-10 administration negatively regulates gonadal maturation in prepubertal testes.\",\n",
      "  \"MESHES\": [\n",
      "    \"Animals\",\n",
      "    \"Dose-Response Relationship, Drug\",\n",
      "    \"Injections, Intraperitoneal\",\n",
      "    \"Kisspeptins\",\n",
      "    \"Male\",\n",
      "    \"Organ Size\",\n",
      "    \"Rats\",\n",
      "    \"Sexual Maturation\",\n",
      "    \"Testis\",\n",
      "    \"Tumor Suppressor Proteins\"\n",
      "  ],\n",
      "  \"final_decision\": \"yes\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "first_key = list(train_data.keys())[0]\n",
    "first_example = train_data[first_key]\n",
    "print(f\"First train example: {json.dumps(first_example, indent=2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
